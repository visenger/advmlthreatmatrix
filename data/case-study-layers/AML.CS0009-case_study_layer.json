{"versions": {"layer": "4.2", "navigator": "4.2"}, "domain": "atlas-v2-+-enterprise-v9-atlas", "name": "Tay Poisoning", "description": "Microsoft created Tay, a twitter chatbot for 18 to 24 year-olds in the U.S. for entertainment purposes. Within 24 hours of its deployment, Tay had to be decommissioned because it tweeted reprehensible words.\n", "techniques": [{"techniqueID": "AML.T0040", "color": "#C8E6C9"}, {"techniqueID": "AML.T0010", "showSubtechniques": true}, {"techniqueID": "AML.T0010.002", "color": "#C8E6C9"}, {"techniqueID": "AML.T0020", "color": "#C8E6C9"}, {"techniqueID": "AML.T0031", "color": "#C8E6C9"}], "legendItems": [{"label": "ATLAS technique", "color": "#C8E6C9"}]}